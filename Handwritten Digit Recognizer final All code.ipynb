{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b51f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision Tree with Default Parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Print the shape of the data\n",
    "print(data.shape)\n",
    "\n",
    "# Features and labels\n",
    "X = data.iloc[:, 1:].values  # Pixel values\n",
    "Y = data.iloc[:, 0].values   # Digit labels\n",
    "\n",
    "# Print the shape of X and Y\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Initializing and training the Decision Tree Classifier\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Select a specific test sample\n",
    "sample_index = 101\n",
    "plt.imshow(X_test[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"True label: {Y_test[sample_index]}\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the digit for the selected test sample\n",
    "predicted_label = classifier.predict(X_test[sample_index].reshape(1, -1))\n",
    "\n",
    "# Print the predicted digit\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n",
    "# Make predictions on the test set\n",
    "Y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96453cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Random Search Optimization to find Best parameters\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = train_data.drop(columns=['label'])  # Features (pixel values)\n",
    "y = train_data['label']  # Labels (the digits)\n",
    "\n",
    "# Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "\n",
    "# Set up the hyperparameter grid for Random Search\n",
    "param_distributions = {\n",
    "    'criterion': ['gini', 'entropy'],     # Splitting criteria\n",
    "    'max_depth': [10, 20, None],          # Maximum depth of the tree\n",
    "    'min_samples_split': [2, 5, 10],      # Minimum samples to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],        # Minimum samples required at a leaf node\n",
    "    'max_features': ['sqrt', 'log2', None]  # Number of features to consider at each split\n",
    "}\n",
    "\n",
    "# Set up RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=dt_classifier,\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=10,            # Number of parameter settings sampled\n",
    "                                   cv=5,                 # 5-fold cross-validation\n",
    "                                   verbose=1,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1)            # Use all available cores\n",
    "\n",
    "# Perform Random Search on the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and print them\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best Parameters found: \", best_params)\n",
    "\n",
    "# Use the best estimator to predict on the test data\n",
    "y_pred = random_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Random Search Optimization: {accuracy * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ecdf30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Best parameter on overall dataset\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "train_data = pd.read_csv('train.csv')\n",
    "\n",
    "# Split the data into features and labels\n",
    "X = train_data.drop(columns=['label'])  # Features (pixel values)\n",
    "y = train_data['label']  # Labels (the digits)\n",
    "\n",
    "# Split into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the best parameters found from Random Search\n",
    "best_params = {\n",
    "    'min_samples_split': 10,\n",
    "    'min_samples_leaf': 2,\n",
    "    'max_features': None,\n",
    "    'max_depth': None,\n",
    "    'criterion': 'entropy'\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree Classifier with the best parameters\n",
    "best_dt_classifier = DecisionTreeClassifier(\n",
    "    min_samples_split=best_params['min_samples_split'],\n",
    "    min_samples_leaf=best_params['min_samples_leaf'],\n",
    "    max_features=best_params['max_features'],\n",
    "    max_depth=best_params['max_depth'],\n",
    "    criterion=best_params['criterion']\n",
    ")\n",
    "\n",
    "# Train the classifier on the complete training set\n",
    "best_dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = best_dt_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy with Best Parameters on Full Dataset: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9356bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest With Default Parameters\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(data.iloc[:, 1:])  # Pixel values (handling NaNs)\n",
    "Y = data.iloc[:, 0].values  # Digit labels\n",
    "\n",
    "# Print the shape of X and Y\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# Initializing and training the Random Forest Classifier with specified parameters\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100,       # Number of trees in the forest\n",
    "    max_depth=10,           # Maximum depth of the tree\n",
    "    min_samples_split=2,    # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=1,     # Minimum number of samples required to be at a leaf node\n",
    "    random_state=42         # Random state for reproducibility\n",
    ")\n",
    "rf_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Select a specific test sample\n",
    "sample_index = 101\n",
    "\n",
    "# Reshape the selected test sample and display it as an image\n",
    "plt.imshow(X_test[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"True label: {Y_test[sample_index]}\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the digit for the selected test sample\n",
    "predicted_label = rf_classifier.predict(X_test[sample_index].reshape(1, -1))\n",
    "\n",
    "# Print the predicted digit\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n",
    "\n",
    "# Make predictions on the entire test set\n",
    "Y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4a67037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Urshali\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\ma\\core.py:2846: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found using RandomizedSearchCV:\n",
      "{'bootstrap': False, 'max_depth': 30, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 363}\n",
      "Accuracy with the best hyperparameters: 0.95\n"
     ]
    }
   ],
   "source": [
    "# Apply random search optimization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Use a subset of the data for faster training (e.g., 20% of the data)\n",
    "data_subset = data.sample(frac=0.2, random_state=42)  # Change frac to adjust the subset size\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(data_subset.iloc[:, 1:])  # Pixel values (handling NaNs)\n",
    "Y = data_subset.iloc[:, 0].values  # Digit labels\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "\n",
    "# Define the hyperparameter space for the Random Forest classifier\n",
    "param_space = {\n",
    "    'n_estimators': randint(50, 500),\n",
    "    'max_depth': randint(10, 50),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 5),\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up the RandomizedSearchCV object\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_distributions=param_space,\n",
    "    n_iter=20,  # Number of parameter settings to sample\n",
    "    scoring='accuracy',\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Run the random search optimization\n",
    "random_search.fit(X_train, Y_train)\n",
    "\n",
    "# Get the best hyperparameters found\n",
    "best_params = random_search.best_params_\n",
    "print(\"Best hyperparameters found using RandomizedSearchCV:\")\n",
    "print(best_params)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "best_rf = random_search.best_estimator_\n",
    "Y_pred = best_rf.predict(X_test)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy with the best hyperparameters: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ab49b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best parameters on full dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(data.iloc[:, 1:])  # Pixel values (handling NaNs)\n",
    "Y = data.iloc[:, 0].values  # Digit labels\n",
    "\n",
    "# Print the shape of X and Y\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\")\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Testing set shape: {X_test.shape}\")\n",
    "\n",
    "# Initializing and training the Random Forest Classifier with specified parameters\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=363,       # Number of trees in the forest\n",
    "    max_depth=30,           # Maximum depth of the tree\n",
    "    min_samples_split=5,    # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=1,     # Minimum number of samples required to be at a leaf node\n",
    "    random_state=42         # Random state for reproducibility\n",
    ")\n",
    "rf_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Select a specific test sample\n",
    "sample_index = 101\n",
    "\n",
    "# Reshape the selected test sample and display it as an image\n",
    "plt.imshow(X_test[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"True label: {Y_test[sample_index]}\")\n",
    "plt.show()\n",
    "\n",
    "# Predict the digit for the selected test sample\n",
    "predicted_label = rf_classifier.predict(X_test[sample_index].reshape(1, -1))\n",
    "\n",
    "# Print the predicted digit\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n",
    "\n",
    "# Make predictions on the entire test set\n",
    "Y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a4acdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN with default parameter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "X = imputer.fit_transform(data.iloc[:, 1:])  # Pixel values (handling NaNs)\n",
    "Y = data.iloc[:, 0].values  # Digit labels \n",
    "\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"Y shape: {Y.shape}\") \n",
    "# Reduce the dataset size to 25% for faster training and testing\n",
    "X_small, _, Y_small, _ = train_test_split(X, Y, test_size=0.75, random_state=9)                                                                                                                              # Splitting the reduced dataset into training and testing sets\n",
    "X_train_small, X_test_small, Y_train_small, Y_test_small = train_test_split(X_small, Y_small, test_size=0.2, random_state=9)\n",
    "print(f\"Training set shape: {X_train_small.shape}\")\n",
    "print(f\"Testing set shape: {X_test_small.shape}\")  \n",
    "\n",
    "# Using 'kd_tree' algorithm for faster neighbor search\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train_small, Y_train_small)                                                                                                                                                                              # Select a specific test sample to visualize\n",
    "sample_index = 101  # Feel free to change this to another index                                                                                                                                              # Reshape the selected test sample and display it as an image\n",
    "plt.imshow(X_test_small[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"True label: {Y_test_small[sample_index]}\")\n",
    "plt.show()\n",
    "# Predict the digit for the selected test sample\n",
    "predicted_label = knn_classifier.predict(X_test_small[sample_index].reshape(1, -1))\n",
    "# Print the predicted digit\n",
    "print(f\"Predicted label: {predicted_label[0]}\")\n",
    "# Make predictions on the entire reduced test set\n",
    "Y_pred_small = knn_classifier.predict(X_test_small)\n",
    "\n",
    "# Calculate the accuracy of the model on the reduced dataset\n",
    "accuracy_small = accuracy_score(Y_test_small, Y_pred_small)\n",
    "\n",
    "\n",
    "# Print the accuracy\n",
    "print(f\"Tuned Model Accuracy on 25% dataset: {accuracy_small:.2f}\")\n",
    "# Splitting the full dataset for final evaluation (optional)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "\n",
    "# Train the same KNN classifier on the full dataset\n",
    "knn_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the full test set\n",
    "Y_pred_full = knn_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the model on the full dataset\n",
    "accuracy_full = accuracy_score(Y_test, Y_pred_full)\n",
    "\n",
    "# Print the accuracy for the full dataset\n",
    "print(f\"Tuned Model Accuracy on full dataset: {accuracy_full:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7d8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search optimization\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.impute import SimpleImputer  # For handling missing values\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Load dataset\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Handle missing values by imputing with the mean\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = imputer.fit_transform(data.iloc[:, 1:])  # Pixel values (handling NaNs)\n",
    "Y = data.iloc[:, 0].values  # Digit labels\n",
    "\n",
    "# Use 25% of the data for hyperparameter tuning\n",
    "X_small, _, Y_small, _ = train_test_split(X, Y, test_size=0.75, random_state=9)\n",
    "\n",
    "# Splitting the smaller dataset into training and testing sets (for tuning only)\n",
    "X_train_small, X_test_small, Y_train_small, Y_test_small = train_test_split(X_small, Y_small, test_size=0.2, random_state=9)\n",
    "\n",
    "# Define the hyperparameter grid for RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_neighbors': randint(3, 10),  # Randomly choose n_neighbors between 3 and 10\n",
    "    'weights': ['uniform', 'distance'],  # Test both uniform and distance weights\n",
    "    'p': randint(1, 3)  # Randomly choose p (1 for Manhattan, 2 for Euclidean)\n",
    "}\n",
    "\n",
    "# Initialize the KNN model\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Perform randomized search with cross-validation (5 folds) on 25% data\n",
    "random_search = RandomizedSearchCV(knn, param_distributions=param_dist, n_iter=10, cv=5, scoring='accuracy', verbose=1, n_jobs=-1, random_state=9)\n",
    "\n",
    "# Fit the model on the smaller training data\n",
    "random_search.fit(X_train_small, Y_train_small)\n",
    "\n",
    "# Print the best hyperparameters found\n",
    "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
    "\n",
    "# Use the best model for prediction on the small test set\n",
    "best_knn = random_search.best_estimator_\n",
    "Y_pred_small = best_knn.predict(X_test_small)\n",
    "\n",
    "# Calculate the accuracy of the tuned model on the small test set\n",
    "accuracy_small = accuracy_score(Y_test_small, Y_pred_small)\n",
    "print(f\"Tuned Model Accuracy on 25% dataset: {accuracy_small:.2f}\")\n",
    "\n",
    "# Once the best hyperparameters are found, train the model on the full dataset\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "\n",
    "# Train the best model on the full dataset\n",
    "best_knn_full = KNeighborsClassifier(**random_search.best_params_)\n",
    "best_knn_full.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the full test set\n",
    "Y_pred_full = best_knn_full.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy on the full dataset\n",
    "accuracy_full = accuracy_score(Y_test, Y_pred_full)\n",
    "print(f\"Tuned Model Accuracy on full dataset: {accuracy_full:.2f}\")\n",
    "\n",
    "# --- Code for predicting and displaying an image ---\n",
    "def display_digit(index, X_test, Y_test, Y_pred_full):\n",
    "    \"\"\" Function to display a digit and its predicted label \"\"\"\n",
    "    img = X_test[index].reshape(28, 28)  # Assuming images are 28x28 pixels\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"True Label: {Y_test[index]}, Predicted: {Y_pred_full[index]}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Choose a random index from the test set\n",
    "random_index = np.random.randint(0, len(X_test))\n",
    "\n",
    "# Display the image with the true and predicted label\n",
    "display_digit(random_index, X_test, Y_test, Y_pred_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c90d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM model\n",
    "\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset (Make sure the path to the CSV file is correct)\n",
    "data = pd.read_csv('train.csv')\n",
    "\n",
    "# Features and labels\n",
    "X = data.iloc[:, 1:].values  # Pixel values (all columns except the first)\n",
    "Y = data.iloc[:, 0].values   # Digit labels (first column)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=9)\n",
    "\n",
    "# Initialize the Support Vector Classifier (SVC)\n",
    "svm = SVC()\n",
    "\n",
    "# Train the model\n",
    "svm.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "Y_pred = svm.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Display an example test image with its predicted label\n",
    "sample_index = 1000\n",
    "plt.imshow(X_test[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"True label: {Y_test[sample_index]}, Predicted label: {Y_pred[sample_index]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b785da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit Recognition using CNN \n",
    "\n",
    "# Step 1: Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Load dataset from CSV file (Use the provided path for train.csv)\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "# Read the training dataset\n",
    "train_data = pd.read_csv(train_path)\n",
    "\n",
    "# Step 3: Preprocessing - split data into features (X) and labels (Y)\n",
    "X = train_data.iloc[:, 1:].values / 255.0  # Normalize pixel values (0-255 -> 0-1)\n",
    "Y = train_data.iloc[:, 0].values           # Labels (digits)\n",
    "\n",
    "# Reshape X to be suitable for CNN (28x28 pixels, 1 color channel for grayscale)\n",
    "X = X.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Step 4: Split data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output neurons (for digits 0-9)\n",
    "])\n",
    "\n",
    "# Step 6: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=5, validation_data=(X_test, Y_test))\n",
    "\n",
    "# Step 8: Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "# Step 9: Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 10: Visualize sample predictions\n",
    "sample_index = 101\n",
    "plt.imshow(X_test[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"True label: {Y_test[sample_index]}, Predicted label: {model.predict(X_test[sample_index].reshape(1, 28, 28, 1)).argmax()}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfd244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Digit Recognition using CNN\n",
    "\n",
    "# Step 1: Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 2: Load dataset from CSV file (Use the provided path for train.csv and test.csv)\n",
    "train_path = 'train.csv'\n",
    "test_path = 'test.csv'\n",
    "\n",
    "# Read the training dataset\n",
    "train_data = pd.read_csv(train_path)\n",
    "\n",
    "# Read the test dataset (which does not have labels)\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "# Step 3: Preprocessing - split training data into features (X) and labels (Y)\n",
    "X_train_full = train_data.iloc[:, 1:].values / 255.0  # Normalize pixel values (0-255 -> 0-1)\n",
    "Y_train_full = train_data.iloc[:, 0].values           # Labels (digits)\n",
    "\n",
    "# Reshape X to be suitable for CNN (28x28 pixels, 1 color channel for grayscale)\n",
    "X_train_full = X_train_full.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# Step 4: Split data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train_full, Y_train_full, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 5: Build the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')  # 10 output neurons (for digits 0-9)\n",
    "])\n",
    "\n",
    "# Step 6: Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 7: Train the model\n",
    "history = model.fit(X_train, Y_train, epochs=5, validation_data=(X_val, Y_val))\n",
    "\n",
    "# Step 8: Evaluate the model on validation set\n",
    "val_loss, val_acc = model.evaluate(X_val, Y_val)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "\n",
    "# Step 9: Preprocess the test data (normalize and reshape for the CNN)\n",
    "X_test = test_data.values / 255.0  # Normalize pixel values\n",
    "X_test = X_test.reshape(-1, 28, 28, 1)  # Reshape for CNN input (28x28 grayscale)\n",
    "\n",
    "# Step 10: Make predictions on the test dataset\n",
    "predictions = model.predict(X_test)\n",
    "predicted_labels = predictions.argmax(axis=1)\n",
    "\n",
    "# Step 11: Create a CSV file with Image ID and corresponding predicted label\n",
    "image_ids = np.arange(1, len(predicted_labels) + 1)  # Generate image IDs starting from 1\n",
    "output_df = pd.DataFrame({'ImageId': image_ids, 'Label': predicted_labels})\n",
    "\n",
    "# Save to CSV file\n",
    "output_df.to_csv('digit_recognizer_predictions.csv', index=False)\n",
    "print(\"Predictions saved to digit_recognizer_predictions.csv\")\n",
    "\n",
    "# Optional: Visualize a sample prediction\n",
    "sample_index = 101\n",
    "plt.imshow(X_test[sample_index].reshape(28, 28), cmap='gray')\n",
    "plt.title(f\"Predicted label: {predicted_labels[sample_index]}\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
